{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning \n",
    "\n",
    "This is an overview of deep learning tools, datasets, papers, and other resources of interest.\n",
    "\n",
    "Updated 2018/08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets - Images\n",
    "\n",
    "  * ImageNet\n",
    "  * COCO\n",
    "  * VOC\n",
    "  * PASCAL\n",
    "  * YFCC100M\n",
    "  * StreetViewHouseNumbers\n",
    "  * YouTube-8M\n",
    "  * OpenImages\n",
    "  * comma.ai's self driving car data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets - NLP\n",
    "\n",
    "  * NLP SOTA Tracking\n",
    "    * https://nlpprogress.com/\n",
    "    * http://ruder.io/tracking-progress-nlp/\n",
    "  * IMDB\n",
    "  * WikiText-2 \n",
    "    * https://einstein.ai/research/the-wikitext-long-term-dependency-language-modeling-dataset\n",
    "    * Includes known SOTA Results\n",
    "  * WikiText-103\n",
    "    * https://einstein.ai/research/the-wikitext-long-term-dependency-language-modeling-dataset\n",
    "    * Includes known SOTA Results\n",
    "  * <others>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets - Reinforcement Learning\n",
    "\n",
    "  * Open AI Gym\n",
    "  * StarCraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Models\n",
    "\n",
    "  * VGG\n",
    "  * ResNet\n",
    "  * GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "  * GAN\n",
    "  * DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative Adversarial Nets <cite data-cite=\"5864161/UW6LMWYU\"></cite>\n",
    "\n",
    "Sum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks <cite data-cite=\"5864161/HGJS53JG\"></cite>\n",
    "\n",
    "Sum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Models\n",
    "\n",
    "  * Embeddings\n",
    "    * word2vec\n",
    "    * doc2vec\n",
    "    * lda2vec\n",
    "  * Sentence Piece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP - MT\n",
    "\n",
    "  * Google Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Papers\n",
    "\n",
    "  * Merity's papers\n",
    "    This papaer catalogues stuff.\n",
    "  * CMSC papers\n",
    "  * Mugan's Blog\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quasi-Recurrent Neural Networks  <cite data-cite=\"5864161/JKGVQJ9A\"></cite>\n",
    "\n",
    "Sum: Alternates convolutional and pooling layers to simulate RNN processing in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization and Optimization Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularizing and Optimizing LSTM Language Models <cite data-cite=\"5864161/IH3AVFE8\"></cite>\n",
    "\n",
    "Sum: LSTM Dropout, Weight Decay, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay <cite data-cite=\"5864161/8RRBQC8U\"></cite>\n",
    "\n",
    "Sum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates <cite data-cite=\"5864161/EVJUVRIR\"></cite>\n",
    "\n",
    "Sum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclical Learning Rates for Training Neural Networks <cite data-cite=\"5864161/DDHQEL5Q\"></cite>\n",
    "\n",
    "Sum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fast.ai\n",
    "\n",
    "  * Lesson 10\n",
    "  * Lesson 11\n",
    "  * Lesson 12\n",
    "  * Lesson 13\n",
    "  * Lesson 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow\n",
    "\n",
    "  * Tensorflow 1.9\n",
    "  * Chollet book\n",
    "  * Hvass Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "5864161/8RRBQC8U": {
     "URL": "http://arxiv.org/abs/1803.09820",
     "abstract": "Although deep learning has produced dazzling successes for applications of image, speech, and video processing in the past few years, most trainings are with suboptimal hyper-parameters, requiring unnecessarily long training times. Setting the hyper-parameters remains a black art that requires years of experience to acquire. This report proposes several efficient ways to set the hyper-parameters that significantly reduce training time and improves performance. Specifically, this report shows how to examine the training validation/test loss function for subtle clues of underfitting and overfitting and suggests guidelines for moving toward the optimal balance point. Then it discusses how to increase/decrease the learning rate/momentum to speed up training. Our experiments show that it is crucial to balance every manner of regularization for each dataset and architecture. Weight decay is used as a sample regularizer to show how its optimal value is tightly coupled with the learning rates and momentums. Files to help replicate the results reported here are available.",
     "accessed": {
      "day": 15,
      "month": 7,
      "year": 2018
     },
     "author": [
      {
       "family": "Smith",
       "given": "Leslie N."
      }
     ],
     "container-title": "arXiv:1803.09820 [cs, stat]",
     "id": "5864161/8RRBQC8U",
     "issued": {
      "day": 26,
      "month": 3,
      "year": 2018
     },
     "note": "arXiv: 1803.09820",
     "shortTitle": "A disciplined approach to neural network hyper-parameters",
     "title": "A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay",
     "title-short": "A disciplined approach to neural network hyper-parameters",
     "type": "article-journal"
    },
    "5864161/DDHQEL5Q": {
     "URL": "http://arxiv.org/abs/1506.01186",
     "abstract": "It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally find the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate \"reasonable bounds\" -- linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.",
     "accessed": {
      "day": 18,
      "month": 6,
      "year": 2018
     },
     "author": [
      {
       "family": "Smith",
       "given": "Leslie N."
      }
     ],
     "container-title": "arXiv:1506.01186 [cs]",
     "id": "5864161/DDHQEL5Q",
     "issued": {
      "day": 3,
      "month": 6,
      "year": 2015
     },
     "note": "arXiv: 1506.01186",
     "title": "Cyclical Learning Rates for Training Neural Networks",
     "type": "article-journal"
    },
    "5864161/EVJUVRIR": {
     "URL": "http://arxiv.org/abs/1708.07120",
     "abstract": "In this paper, we describe a phenomenon, which we named \"super-convergence\", where neural networks can be trained an order of magnitude faster than with standard training methods. The existence of super-convergence is relevant to understanding why deep networks generalize well. One of the key elements of super-convergence is training with one learning rate cycle and a large maximum learning rate. A primary insight that allows super-convergence training is that large learning rates regularize the training, hence requiring a reduction of all other forms of regularization in order to preserve an optimal regularization balance. We also derive a simplification of the Hessian Free optimization method to compute an estimate of the optimal learning rate. Experiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet datasets, and resnet, wide-resnet, densenet, and inception architectures. In addition, we show that super-convergence provides a greater boost in performance relative to standard training when the amount of labeled training data is limited. The architectures and code to replicate the figures in this paper are available at github.com/lnsmith54/super-convergence. See http://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of super-convergence to win the DAWNBench challenge (see https://dawn.cs.stanford.edu/benchmark/).",
     "accessed": {
      "day": 15,
      "month": 7,
      "year": 2018
     },
     "author": [
      {
       "family": "Smith",
       "given": "Leslie N."
      },
      {
       "family": "Topin",
       "given": "Nicholay"
      }
     ],
     "container-title": "arXiv:1708.07120 [cs, stat]",
     "id": "5864161/EVJUVRIR",
     "issued": {
      "day": 23,
      "month": 8,
      "year": 2017
     },
     "note": "arXiv: 1708.07120",
     "shortTitle": "Super-Convergence",
     "title": "Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates",
     "title-short": "Super-Convergence",
     "type": "article-journal"
    },
    "5864161/HGJS53JG": {
     "URL": "http://arxiv.org/abs/1511.06434",
     "abstract": "In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.",
     "accessed": {
      "day": 23,
      "month": 7,
      "year": 2018
     },
     "author": [
      {
       "family": "Radford",
       "given": "Alec"
      },
      {
       "family": "Metz",
       "given": "Luke"
      },
      {
       "family": "Chintala",
       "given": "Soumith"
      }
     ],
     "container-title": "arXiv:1511.06434 [cs]",
     "id": "5864161/HGJS53JG",
     "issued": {
      "day": 19,
      "month": 11,
      "year": 2015
     },
     "note": "arXiv: 1511.06434",
     "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
     "type": "article-journal"
    },
    "5864161/I53VTZ36": {
     "author": [
      {
       "family": "Goodfellow",
       "given": "Ian"
      },
      {
       "family": "Pouget-Abadie",
       "given": "Jean"
      },
      {
       "family": "Mirza",
       "given": "Mehdi"
      },
      {
       "family": "Xu",
       "given": "Bing"
      },
      {
       "family": "Warde-Farley",
       "given": "David"
      },
      {
       "family": "Ozair",
       "given": "Sherjil"
      },
      {
       "family": "Courville",
       "given": "Aaron"
      },
      {
       "family": "Bengio",
       "given": "Yoshua"
      }
     ],
     "id": "5864161/I53VTZ36",
     "language": "en",
     "page": "9",
     "page-first": "9",
     "title": "Generative Adversarial Nets",
     "type": "article-journal"
    },
    "5864161/IH3AVFE8": {
     "URL": "http://arxiv.org/abs/1708.02182",
     "abstract": "Recurrent neural networks (RNNs), such as long short-term memory networks (LSTMs), serve as a fundamental building block for many sequence learning tasks, including machine translation, language modeling, and question answering. In this paper, we consider the specific problem of word-level language modeling and investigate strategies for regularizing and optimizing LSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on hidden-to-hidden weights as a form of recurrent regularization. Further, we introduce NT-ASGD, a variant of the averaged stochastic gradient method, wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. Using these and other regularization strategies, we achieve state-of-the-art word level perplexities on two data sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the effectiveness of a neural cache in conjunction with our proposed model, we achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and 52.0 on WikiText-2.",
     "accessed": {
      "day": 6,
      "month": 7,
      "year": 2018
     },
     "author": [
      {
       "family": "Merity",
       "given": "Stephen"
      },
      {
       "family": "Keskar",
       "given": "Nitish Shirish"
      },
      {
       "family": "Socher",
       "given": "Richard"
      }
     ],
     "container-title": "arXiv:1708.02182 [cs]",
     "id": "5864161/IH3AVFE8",
     "issued": {
      "day": 7,
      "month": 8,
      "year": 2017
     },
     "note": "arXiv: 1708.02182",
     "title": "Regularizing and Optimizing LSTM Language Models",
     "type": "article-journal"
    },
    "5864161/JKGVQJ9A": {
     "URL": "http://arxiv.org/abs/1611.01576",
     "abstract": "Recurrent neural networks are a powerful tool for modeling sequential data, but the dependence of each timestep's computation on the previous timestep's output limits parallelism and makes RNNs unwieldy for very long sequences. We introduce quasi-recurrent neural networks (QRNNs), an approach to neural sequence modeling that alternates convolutional layers, which apply in parallel across timesteps, and a minimalist recurrent pooling function that applies in parallel across channels. Despite lacking trainable recurrent layers, stacked QRNNs have better predictive accuracy than stacked LSTMs of the same hidden size. Due to their increased parallelism, they are up to 16 times faster at train and test time. Experiments on language modeling, sentiment classification, and character-level neural machine translation demonstrate these advantages and underline the viability of QRNNs as a basic building block for a variety of sequence tasks.",
     "accessed": {
      "day": 23,
      "month": 7,
      "year": 2018
     },
     "author": [
      {
       "family": "Bradbury",
       "given": "James"
      },
      {
       "family": "Merity",
       "given": "Stephen"
      },
      {
       "family": "Xiong",
       "given": "Caiming"
      },
      {
       "family": "Socher",
       "given": "Richard"
      }
     ],
     "container-title": "arXiv:1611.01576 [cs]",
     "id": "5864161/JKGVQJ9A",
     "issued": {
      "day": 4,
      "month": 11,
      "year": 2016
     },
     "note": "arXiv: 1611.01576",
     "title": "Quasi-Recurrent Neural Networks",
     "type": "article-journal"
    },
    "5864161/UW6LMWYU": {
     "URL": "http://arxiv.org/abs/1406.2661",
     "abstract": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.",
     "accessed": {
      "day": 23,
      "month": 7,
      "year": 2018
     },
     "author": [
      {
       "family": "Goodfellow",
       "given": "Ian J."
      },
      {
       "family": "Pouget-Abadie",
       "given": "Jean"
      },
      {
       "family": "Mirza",
       "given": "Mehdi"
      },
      {
       "family": "Xu",
       "given": "Bing"
      },
      {
       "family": "Warde-Farley",
       "given": "David"
      },
      {
       "family": "Ozair",
       "given": "Sherjil"
      },
      {
       "family": "Courville",
       "given": "Aaron"
      },
      {
       "family": "Bengio",
       "given": "Yoshua"
      }
     ],
     "container-title": "arXiv:1406.2661 [cs, stat]",
     "id": "5864161/UW6LMWYU",
     "issued": {
      "day": 10,
      "month": 6,
      "year": 2014
     },
     "note": "arXiv: 1406.2661",
     "title": "Generative Adversarial Networks",
     "type": "article-journal"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
